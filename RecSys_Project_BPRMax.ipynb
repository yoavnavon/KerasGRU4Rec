{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecSys Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b322bbbb4a0f4a408d5287672af3c332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_44b5fcdb193b4655a9f8366e825ce24c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c7a2cc5630d4f59b99a116d8b0ae07d",
              "IPY_MODEL_eb4adf5256a64083a454dedef70ff5c4"
            ]
          }
        },
        "44b5fcdb193b4655a9f8366e825ce24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c7a2cc5630d4f59b99a116d8b0ae07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af45d0b675604b64a374dde26777df15",
            "_dom_classes": [],
            "description": "Epoch 1. Batch 1000. Loss: 5.61464: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6950a874d1f43278ec0d8fd7e038288"
          }
        },
        "eb4adf5256a64083a454dedef70ff5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdebc448b4da45e78118396af81e6d38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [04:34&lt;00:00,  3.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3b73aea3018428994707e67f7e503ce"
          }
        },
        "af45d0b675604b64a374dde26777df15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6950a874d1f43278ec0d8fd7e038288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdebc448b4da45e78118396af81e6d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3b73aea3018428994707e67f7e503ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbe3f3f364d3401aa21de060745f2be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54b447252daf402b94a444cc01971912",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e59ae0760ec4b29b33512b43dc7224b",
              "IPY_MODEL_7292c118c9284618a2e3a319fbe49baf"
            ]
          }
        },
        "54b447252daf402b94a444cc01971912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e59ae0760ec4b29b33512b43dc7224b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d7a96f85e32476081726c05472e7a1f",
            "_dom_classes": [],
            "description": "Epoch 1. Batch 1796. Loss: 5.57454:  80%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_848817129ebc4a56bfe7db2f36f7e8e4"
          }
        },
        "7292c118c9284618a2e3a319fbe49baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f66b4a3c4654dff8a34ab70e8a7293f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 796/1000 [02:38&lt;00:40,  5.05it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7156bdf26dc248f5ac80255c57261205"
          }
        },
        "2d7a96f85e32476081726c05472e7a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "848817129ebc4a56bfe7db2f36f7e8e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f66b4a3c4654dff8a34ab70e8a7293f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7156bdf26dc248f5ac80255c57261205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoavnavon/KerasGRU4Rec/blob/master/RecSys_Project_BPRMax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rONF6XadEcn4",
        "colab_type": "text"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XZ5g6qMCvJo",
        "colab_type": "code",
        "outputId": "2669be71-3974-4eb0-d00f-16da91faf1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# Test Set\n",
        "#!wget https://os.zhdk.cloud.switch.ch/swift/v1/crowdai-public/spotify-sequential-skip-prediction-challenge/20181113_test_set.tar.gz\n",
        "\n",
        "# Track Features\n",
        "!wget https://os.zhdk.cloud.switch.ch/swift/v1/crowdai-public/spotify-sequential-skip-prediction-challenge/20181120_track_features.tar.gz\n",
        "!tar -xzf 20181120_track_features.tar.gz  \n",
        "# Train/Track features mini\n",
        "#!wget https://aicrowd-production.s3.eu-central-1.amazonaws.com/dataset_files/challenge_25/0654d015-d4b4-4357-8040-6a846dec093d_training_set_track_features_mini.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAJ6IZH6GWKDCCDFAQ%2F20191020%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20191020T164401Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=ce4298b9f121882f75f1093213756ec9ddec50025bf574a7f132972c8872a418\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-12 20:30:43--  https://os.zhdk.cloud.switch.ch/swift/v1/crowdai-public/spotify-sequential-skip-prediction-challenge/20181120_track_features.tar.gz\n",
            "Resolving os.zhdk.cloud.switch.ch (os.zhdk.cloud.switch.ch)... 86.119.32.16, 2001:620:5ca1:101::1:125\n",
            "Connecting to os.zhdk.cloud.switch.ch (os.zhdk.cloud.switch.ch)|86.119.32.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971105878 (926M) [application/gzip]\n",
            "Saving to: â€˜20181120_track_features.tar.gzâ€™\n",
            "\n",
            "20181120_track_feat 100%[===================>] 926.12M  9.85MB/s    in 97s     \n",
            "\n",
            "2019-12-12 20:32:21 (9.55 MB/s) - â€˜20181120_track_features.tar.gzâ€™ saved [971105878/971105878]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyifW4F1kniI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d990250f-eb67-4360-84e1-ba8cac4f7502",
        "id": "5fOdDGSi-1kI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "!pip install tqdm --upgrade"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/32/5144caf0478b1f26bd9d97f510a47336cf4ac0f96c6bc3b5af20d4173920/tqdm-4.40.2-py2.py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 10kB 28.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 20kB 31.4MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 30kB 37.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 40kB 40.6MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 51kB 28.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.5MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed tqdm-4.40.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsxP-X07-6eM",
        "colab_type": "code",
        "outputId": "dfee016e-7517-4204-e37d-d6f42ac61d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!mkdir -p data data/training data/testing\n",
        "!wget https://recsys-spotify.s3.amazonaws.com/training_subsample_1.tar.gz\n",
        "!tar -xzf training_subsample_1.tar.gz -C data/\n",
        "!mv data/log_3_20180827_000000000000.csv.gz data/training/log_3_20180827_000000000000.csv.gz"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-12 20:32:52--  https://recsys-spotify.s3.amazonaws.com/training_subsample_1.tar.gz\n",
            "Resolving recsys-spotify.s3.amazonaws.com (recsys-spotify.s3.amazonaws.com)... 52.216.108.115\n",
            "Connecting to recsys-spotify.s3.amazonaws.com (recsys-spotify.s3.amazonaws.com)|52.216.108.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 544881679 (520M) [binary/octet-stream]\n",
            "Saving to: â€˜training_subsample_1.tar.gzâ€™\n",
            "\n",
            "training_subsample_ 100%[===================>] 519.64M  14.0MB/s    in 39s     \n",
            "\n",
            "2019-12-12 20:33:32 (13.3 MB/s) - â€˜training_subsample_1.tar.gzâ€™ saved [544881679/544881679]\n",
            "\n",
            "tar: Removing leading `/' from member names\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbRwBZLIBb-A",
        "colab_type": "text"
      },
      "source": [
        "#Â Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpB30R1aYBv0",
        "colab_type": "text"
      },
      "source": [
        "### Get Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj0B-ZfcYIXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def create_test_split(training_file,testing_file):\n",
        "  train = pd.read_csv(training_file)\n",
        "  test = pd.read_csv(testing_file)\n",
        "  mask = item_is_in(test, train)\n",
        "  test = test[mask]\n",
        "  basename = os.path.basename(testing_file)\n",
        "  test.to_csv(f'data/testing/{basename}')\n",
        "  del train\n",
        "  del test\n",
        "  del mask\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxQIg3rTbq1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def item_is_in(test, train):\n",
        "  items = set()\n",
        "  for i in train.track_id_clean.unique():\n",
        "    items.add(i)\n",
        "  mask = []\n",
        "  for i in test.track_id_clean:\n",
        "    mask.append(i in items)\n",
        "  del items\n",
        "  return np.array(mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlj80SadZLrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_file = 'data/training/log_3_20180827_000000000000.csv.gz'\n",
        "testing_file = 'data/log_1_20180715_000000000000.csv.gz'\n",
        "\n",
        "create_test_split(training_file, testing_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuxT1YlHSqr0",
        "colab_type": "text"
      },
      "source": [
        "### Get Item Idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B_Xdv-B5lv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "\n",
        "def get_item_idxs(input_path):\n",
        "  items = {}\n",
        "  item_idx = 0\n",
        "  for path in tqdm(glob(f'{input_path}/*.csv.gz')):\n",
        "    df = pd.read_csv(path)\n",
        "    for track in df.track_id_clean.unique():\n",
        "      if track not in items:\n",
        "        items[track] = item_idx\n",
        "        item_idx += 1\n",
        "    del df\n",
        "  with open('item_idxs.json','w') as file:\n",
        "    json.dump(items, file)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tGIMFVRSzYE",
        "colab_type": "code",
        "outputId": "30bb758b-021f-4ef0-c9b4-02cd887da5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_path = 'data/training'\n",
        "get_item_idxs(input_path)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.75s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZviKv3y-k9XA",
        "colab_type": "text"
      },
      "source": [
        "### Get Track Feats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX6921Eck8lA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tracks0 = pd.read_csv('track_features/tf_000000000000.csv')\n",
        "tracks1 = pd.read_csv('track_features/tf_000000000001.csv')\n",
        "items_idxs = json.load(open('item_idxs.json','r'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_WdVduJlTgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mask = []\n",
        "for i in tracks0['track_id']:\n",
        "  mask.append(i in items_idxs)\n",
        "mask0 = np.array(mask)\n",
        "tracks0 = tracks0[mask0]\n",
        "\n",
        "mask = []\n",
        "for i in tracks1['track_id']:\n",
        "  mask.append(i in items_idxs)\n",
        "mask1 = np.array(mask)\n",
        "tracks1 = tracks1[mask1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEITPHdGmPiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "track_feats = pd.concat([tracks0,tracks1])\n",
        "track_feats = track_feats.drop('mode', axis=1)\n",
        "track_feats['idx'] = track_feats['track_id'].apply(lambda x: items_idxs[x])\n",
        "track_feats = track_feats.drop('track_id', axis=1)\n",
        "track_feats = track_feats.set_index('idx')\n",
        "track_feats_std = pd.DataFrame(StandardScaler().fit_transform(track_feats), index=track_feats.index)\n",
        "track_feats_std.to_csv('tracks_feats.csv', index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkElsu2cPXHA",
        "colab_type": "text"
      },
      "source": [
        "# Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0BNdicdHBu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "class SessionDataset:\n",
        "  \n",
        "  def __init__(self, data_path, idxs_path,session_key=None, item_key=None):\n",
        "    self.filenames = glob(f'{data_path}/*.csv.gz')\n",
        "    self.item_idxs = json.load(open(idxs_path))\n",
        "    self.session_key = session_key\n",
        "    self.item_key = item_key\n",
        "    self.n_items = len(self.item_idxs)\n",
        "    self.data_path = data_path\n",
        "    \n",
        "class SessionDataLoader:\n",
        "  def __init__(self, dataset, batch_size):\n",
        "    self.filenames = dataset.filenames[:]\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.loader = None\n",
        "    \n",
        "  def __iter__(self):\n",
        "    dataset = self.dataset\n",
        "    filenames = self.filenames\n",
        "    while filenames or self.loader:\n",
        "      if not self.loader:\n",
        "        filename = filenames.pop()\n",
        "        df = pd.read_csv(filename)\n",
        "        df = df[['session_id','track_id_clean']]\n",
        "        dataset = SessionDatasetMini(\n",
        "            df,\n",
        "            session_key=dataset.session_key,\n",
        "            item_key=dataset.item_key,\n",
        "            item_idxs=dataset.item_idxs)\n",
        "        loader = SessionDataLoaderMini(dataset, batch_size=self.batch_size)\n",
        "        self.loader = loader\n",
        "      loader = self.loader\n",
        "      for feat, target, mask in loader:\n",
        "        yield feat, target, mask\n",
        "      self.loader = None\n",
        "      del loader\n",
        "      del dataset\n",
        "      del df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqDin_J2PWFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SessionDatasetMini:\n",
        "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"    \n",
        "    def __init__(self, data, session_key='SessionId', item_key='ItemId', item_idxs=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: path of the csv file\n",
        "            sep: separator for the csv\n",
        "            session_key, item_key, time_key: name of the fields corresponding to the sessions, items, time\n",
        "            n_samples: the number of samples to use. If -1, use the whole dataset.\n",
        "            itemmap: mapping between item IDs and item indices\n",
        "            time_sort: whether to sort the sessions by time or not\n",
        "        \"\"\"\n",
        "        self.df = data\n",
        "        self.session_key = session_key\n",
        "        self.item_key = item_key\n",
        "        self.click_offsets = self.get_click_offsets()\n",
        "        self.session_idx_arr = self.order_session_idx()\n",
        "        self.item_idxs = item_idxs\n",
        "        self.add_item_idxs()\n",
        "        \n",
        "    def add_item_idxs(self):\n",
        "        self.df['item_idx'] = self.df[self.item_key].apply(lambda x: self.item_idxs[x])\n",
        "        \n",
        "    def get_click_offsets(self):\n",
        "        \"\"\"\n",
        "        Return the offsets of the beginning clicks of each session IDs,\n",
        "        where the offset is calculated against the first click of the first session ID.\n",
        "        \"\"\"\n",
        "        offsets = np.zeros(self.df[self.session_key].nunique() + 1, dtype=np.int32)\n",
        "        # group & sort the df by session_key and get the offset values\n",
        "        offsets[1:] = self.df.groupby(self.session_key).size().cumsum()\n",
        "\n",
        "        return offsets\n",
        "\n",
        "    def order_session_idx(self):\n",
        "        \"\"\" Order the session indices \"\"\"\n",
        "        session_idx_arr = np.arange(self.df[self.session_key].nunique())\n",
        "        return session_idx_arr\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCT-HBG4Hiyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SessionDataLoaderMini:\n",
        "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"    \n",
        "    def __init__(self, dataset, batch_size=50):\n",
        "        \"\"\"\n",
        "        A class for creating session-parallel mini-batches.\n",
        "        Args:\n",
        "            dataset (SessionDataset): the session dataset to generate the batches from\n",
        "            batch_size (int): size of the batch\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.done_sessions_counter = 0\n",
        "        self.sum = 0\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
        "        Yields:\n",
        "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
        "            target (B,): a Variable that stores the target item indices\n",
        "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
        "        \"\"\"\n",
        "        df = self.dataset.df\n",
        "        session_key= self.dataset.session_key\n",
        "        item_key= self.dataset.item_key\n",
        "        self.n_items = df[item_key].nunique()+1\n",
        "        click_offsets = self.dataset.click_offsets\n",
        "        session_idx_arr = self.dataset.session_idx_arr\n",
        "\n",
        "        iters = np.arange(self.batch_size)\n",
        "        maxiter = iters.max()\n",
        "        start = click_offsets[session_idx_arr[iters]] # start idx of every session\n",
        "        end = click_offsets[session_idx_arr[iters] + 1] # end idx of every session\n",
        "        mask = [] # indicator for the sessions to be terminated\n",
        "        finished = False        \n",
        "\n",
        "        while not finished:\n",
        "            minlen = (end - start).min() # Minimum session length\n",
        "            # Item indices (for embedding) for clicks where the first sessions start\n",
        "            idx_target = df.item_idx.values[start]\n",
        "            \n",
        "            for i in range(minlen):\n",
        "                if i >= 1:\n",
        "                  self.done_sessions_counter = 0\n",
        "                # Build inputs & targets\n",
        "                idx_input = idx_target\n",
        "                idx_target = df.item_idx.values[start + i + 1]\n",
        "                inp = idx_input\n",
        "                target = idx_target\n",
        "                yield inp, target, mask\n",
        "                \n",
        "            # click indices where a particular session meets second-to-last element\n",
        "            start = start + (minlen - 1)\n",
        "\n",
        "            # see if how many sessions should terminate\n",
        "            mask = np.arange(len(iters))[(end - start) <= 1]\n",
        "            self.done_sessions_counter = len(mask)\n",
        "            for idx in mask:\n",
        "                maxiter += 1\n",
        "                if maxiter >= len(click_offsets) - 1:\n",
        "                    finished = True\n",
        "                    break\n",
        "                # update the next starting/ending point\n",
        "                iters[idx] = maxiter\n",
        "                start[idx] = click_offsets[session_idx_arr[maxiter]]\n",
        "                end[idx] = click_offsets[session_idx_arr[maxiter] + 1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1tAMcE-KTsk",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDSem-R-KV0g",
        "colab_type": "code",
        "outputId": "f4e0c7b1-7b7c-46fa-e5a2-2e92ef924db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Input, Dense, Dropout, CuDNNGRU, Embedding"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGY8gnCRYYqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRU4REC:\n",
        "  \n",
        "  def __init__(self, args, n_items):\n",
        "    self.optimizer = keras.optimizers.Adam(lr=args.lr, beta_1=args.beta_1, beta_2=args.beta_2, epsilon=None, amsgrad=False)\n",
        "    self.activation = args.activation\n",
        "    self.batch_size = args.batch_size\n",
        "    self.emb_size = args.emb_size\n",
        "    self.dropout = args.dropout\n",
        "    self.hidden_units = args.hidden_units\n",
        "    self.n_items = n_items\n",
        "    self.loss = self.set_loss(args.loss)\n",
        "    self.regularizer = regularizers.l2(args.regularization) if args.regularization else None\n",
        "    self.set_input(args.input_form)\n",
        "    self.model = self.create_model()\n",
        "    \n",
        "    \n",
        "  \n",
        "  def create_model(self):   \n",
        "    inputs = self.first_layer\n",
        "    gru, gru_states = CuDNNGRU(self.hidden_units, stateful=True, return_state=True, kernel_regularizer=self.regularizer)(inputs)\n",
        "    drop2 = Dropout(self.dropout)(gru)\n",
        "    predictions = Dense(self.n_items, activation=self.activation, kernel_regularizer=self.regularizer)(drop2)\n",
        "    model = Model(input=self.input, output=[predictions])\n",
        "    model.compile(loss=self.loss, optimizer=self.optimizer)\n",
        "    model.summary()\n",
        "    return model    \n",
        "\n",
        "  def set_loss(self, loss):\n",
        "    if loss == 'bpr':\n",
        "      return bpr\n",
        "    \n",
        "    if loss == 'crossentropy':\n",
        "      return categorical_crossentropy\n",
        "    \n",
        "    if loss == 'bpr-max':\n",
        "      return _bpr_max#(0.0001, self.batch_size)\n",
        "    \n",
        "  def set_input(self, input_form):\n",
        "    if input_form == 'one-hot':\n",
        "      self.input = Input(batch_shape=(self.batch_size, 1, self.n_items))\n",
        "      self.first_layer = self.input\n",
        "    if input_form == 'emb':\n",
        "      self.input = Input(batch_shape=(self.batch_size, 1))\n",
        "      self.first_layer = Embedding(self.n_items, self.emb_size)(self.input)\n",
        "    if input_form == 'content':\n",
        "      self.input = Input(batch_shape=(self.batch_size, 1, 28))\n",
        "      self.first_layer = self.input\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qocDH232KUgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bpr(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true,[-1]) # flatten for gather (b,1) -> (b,)\n",
        "  y_true = tf.cast(y_true, tf.int32)\n",
        "  gather = tf.gather(y_pred,y_true, axis=1) # get positive and negative scores\n",
        "  diag = tf.diag_part(gather) # positive samples\n",
        "  diag_exp = tf.expand_dims(diag, axis=0) # expand dim to transpose\n",
        "  trans = tf.transpose(diag_exp) \n",
        "  diff = trans - gather # diference between positive and all\n",
        "  sig = tf.nn.sigmoid(diff)\n",
        "  loss = tf.reduce_mean(-tf.log(sig))\n",
        "  return loss\n",
        "\n",
        "def softmax_neg(logits, batch_size):\n",
        "  mask = tf.cast(1,tf.float32) - tf.eye(batch_size, batch_size, dtype=tf.float32)\n",
        "  neg_scores = mask * logits\n",
        "  diff = neg_scores - tf.reduce_max(neg_scores, axis=1)\n",
        "  exp = tf.math.exp(diff) * mask\n",
        "  softmaxed = exp / tf.reduce_sum(exp, axis=1)\n",
        "  return softmaxed\n",
        "\n",
        "#def bpr_max(bpr_reg, batch_size):\n",
        "def _bpr_max(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true,[-1])\n",
        "  y_true = tf.cast(y_true, tf.int32)\n",
        "  gather = tf.gather(y_pred,y_true, axis=1) # get positive and negative scores, gather=yhat\n",
        "  y_softmax = softmax_neg(gather, 64)\n",
        "  diag = tf.diag_part(gather) # positive samples\n",
        "  diag_exp = tf.expand_dims(diag, axis=0) # expand dim to transpose\n",
        "  trans = tf.transpose(diag_exp) \n",
        "  diff = trans - gather\n",
        "  sig = tf.nn.sigmoid(diff) * y_softmax\n",
        "  reg = 0.0001 * tf.reduce_sum(((gather**2)*y_softmax), axis=1)\n",
        "  loss = tf.reduce_mean(-tf.log(sig + 1e-24) + reg)\n",
        "  return loss\n",
        "  #return _bpr_max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Baeojer1VJls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MostPopular:\n",
        "  \n",
        "  def __init__(self, dataset_train):\n",
        "    self.train = dataset_train.df\n",
        "    self.most_popular = None\n",
        "    self.get_most_popular()\n",
        "    self.model = self\n",
        "  \n",
        "  def get_most_popular(self):\n",
        "    grouped = self.train.groupby('item_idx').count()['session_id']\n",
        "    items = grouped.sort_values(ascending=False)\n",
        "    self.most_popular = np.zeros((len(items),))\n",
        "    for i in range(len(items)):\n",
        "      self.most_popular[i] = items[i]\n",
        "    \n",
        "  def predict(self, input_oh, batch_size=64):\n",
        "    return np.repeat(self.most_popular[None], batch_size, axis=0)\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqCqS-_3KhWA",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-8ZZi047GmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJYTulblKm9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_states(model):\n",
        "    return [K.get_value(s) for s,_ in model.state_updates]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoP1ibO9MBF8",
        "colab_type": "text"
      },
      "source": [
        "### get_metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olha-9RjdyYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def get_metrics(model, loader, args, k=20):\n",
        "\n",
        "    rec_sum = 0.0\n",
        "    mrr_sum = 0.0\n",
        "    rec_sum_alt = 0.0\n",
        "    mrr_sum_alt = 0.0\n",
        "    batch = 0\n",
        "    batch_size = args.batch_size\n",
        "    n_items = loader.dataset.n_items\n",
        "    tracks_feats = pd.read_csv('tracks_feats.csv',index_col=0)\n",
        "    for feat, label, mask in loader:\n",
        "        target_oh = to_categorical(label, num_classes=n_items) # [batch_size, n_classes]\n",
        "        if args.input_form == 'one-hot':\n",
        "          input_oh  = to_categorical(feat,  num_classes=n_items) # [batch_size, n_classes]\n",
        "          input_oh = np.expand_dims(input_oh, axis=1) # [batch_size, 1, n_clasess]\n",
        "          feat = input_oh\n",
        "        if args.input_form == 'content':\n",
        "          feat = tracks_feats.loc[feat,:].values\n",
        "          feat = np.expand_dims(feat, axis=1)\n",
        "          \n",
        "        pred = model.predict(feat, batch_size=batch_size) #[batch_size, n_classes]\n",
        "        \n",
        "        # get values, index pairs\n",
        "        partition = np.partition(pred, -k, axis=1)[:,-k:]\n",
        "        arg_partition = np.argpartition(pred, -k, axis=1)[:,-k:]\n",
        "        stack = np.stack([partition, arg_partition],axis=2)\n",
        "        \n",
        "        # sorted values indexes\n",
        "        index = stack[:,:,0].argsort(axis=1)[:,:,None]\n",
        "        \n",
        "        # take based on sorted values indexes\n",
        "        topk = np.take_along_axis(stack,index,axis=1)[:,:,1].astype(int)\n",
        "        \n",
        "        # relevant mask\n",
        "        mask = np.repeat(label,k).reshape(batch_size, k) == topk\n",
        "        \n",
        "        # weights for mrr\n",
        "        weights = np.arange(1,k + 1)\n",
        "        \n",
        "        # compute based on relevant and weights (mrr only)\n",
        "        rec_sum_alt += mask.sum()\n",
        "        mrr_sum_alt += (mask / weights).sum()\n",
        "        batch += 1\n",
        "\n",
        "        if batch == args.n_batch_validate:\n",
        "          break\n",
        "\n",
        "    recall = rec_sum_alt / (batch * batch_size)\n",
        "    mrr = mrr_sum_alt / (batch * batch_size)\n",
        "    return (recall, mrr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOvBi4QDkms4",
        "colab_type": "text"
      },
      "source": [
        "### train_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7fskb6YYjSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(args):\n",
        "    dataset = SessionDataset(\n",
        "        args.data_path,\n",
        "        args.idxs_path,\n",
        "        session_key=args.session_key,\n",
        "        item_key=args.item_key)\n",
        "    \n",
        "    test_dataset = SessionDataset(\n",
        "        args.test_path,\n",
        "        args.idxs_path,\n",
        "        session_key=args.session_key,\n",
        "        item_key=args.item_key)\n",
        "    \n",
        "    test_loader = SessionDataLoader(test_dataset, batch_size=args.batch_size)\n",
        "    \n",
        "    \n",
        "    model_to_train = GRU4REC(args, dataset.n_items)\n",
        "    batch_size = args.batch_size\n",
        "    \n",
        "    epoch = 0\n",
        "    batch = 0\n",
        "    rnn_idx = 2 if args.input_form == 'emb' else 1\n",
        "    \n",
        "    tracks_feats = pd.read_csv('tracks_feats.csv',index_col=0)\n",
        "    \n",
        "    for epoch in range(1, args.epochs):\n",
        "        t = tqdm(total=args.validate_batch)\n",
        "        loader = SessionDataLoader(dataset, batch_size=batch_size)\n",
        "        for feat, target, mask in loader:\n",
        "            real_mask = np.ones((batch_size, 1))\n",
        "            for elt in mask:\n",
        "                real_mask[elt, :] = 0\n",
        "            hidden_states = get_states(model_to_train.model)[0]\n",
        "            hidden_states = np.multiply(real_mask, hidden_states)\n",
        "            hidden_states = np.array(hidden_states, dtype=np.float32)\n",
        "            model_to_train.model.layers[rnn_idx].reset_states(hidden_states)\n",
        "            if args.input_form == 'one-hot':\n",
        "              input_oh = to_categorical(feat, num_classes=dataset.n_items) \n",
        "              input_oh = np.expand_dims(input_oh, axis=1)\n",
        "              feat = input_oh\n",
        "            if args.input_form == 'content':\n",
        "              feat = tracks_feats.loc[feat,:].values\n",
        "              feat = np.expand_dims(feat, axis=1)\n",
        "            if args.loss == 'crossentropy':\n",
        "              target = to_categorical(target, num_classes=dataset.n_items)\n",
        "            tr_loss = model_to_train.model.train_on_batch(feat, target)\n",
        "            \n",
        "            batch += 1\n",
        "            t.set_description(\"Epoch {0}. Batch {1}. Loss: {2:.5f}\".format(epoch,batch, tr_loss))\n",
        "            t.update(1)\n",
        "            if not batch % 100 and False:\n",
        "              pred = model_to_train.model.predict(feat, batch_size=batch_size)\n",
        "              print(pred)\n",
        "            if not batch % args.validate_batch:\n",
        "              print(\"\\nEvaluating Model\")\n",
        "              rec, mrr = get_metrics(model_to_train.model,test_loader, args)\n",
        "              print(\"Recall@{}: {:5f}\".format(args.topk, rec))\n",
        "              print(\"MRR@{}: {:5f}\".format(args.topk, mrr))\n",
        "              print(\"\\n\")\n",
        "              t.close()\n",
        "              t = tqdm(total=args.validate_batch)\n",
        "              #t.reset()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLCBTbKKzZgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_most_popular(args):\n",
        "  train_dataset = SessionDataset(\n",
        "        args.train_data,\n",
        "        session_key=args.session_key,\n",
        "        item_key=args.item_key)\n",
        "  model = MostPopular(train_dataset)\n",
        "  (rec, rec_k), (mrr, mrr_k) = get_metrics(model, args, train_dataset.itemmap)\n",
        "  print(\"\\nRecall@{}: {:5f}\".format(rec_k, rec))\n",
        "  print(\"MRR@{}: {:5f}\".format(mrr_k, mrr))\n",
        "  print(\"\\n\")\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGNeQbMXLHmQ",
        "colab_type": "text"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P94Hav9P2iQ0",
        "colab_type": "code",
        "outputId": "3857d534-2aff-4a8c-9fa9-d0d9d2ba3df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846,
          "referenced_widgets": [
            "b322bbbb4a0f4a408d5287672af3c332",
            "44b5fcdb193b4655a9f8366e825ce24c",
            "8c7a2cc5630d4f59b99a116d8b0ae07d",
            "eb4adf5256a64083a454dedef70ff5c4",
            "af45d0b675604b64a374dde26777df15",
            "d6950a874d1f43278ec0d8fd7e038288",
            "bdebc448b4da45e78118396af81e6d38",
            "b3b73aea3018428994707e67f7e503ce",
            "dbe3f3f364d3401aa21de060745f2be1",
            "54b447252daf402b94a444cc01971912",
            "7e59ae0760ec4b29b33512b43dc7224b",
            "7292c118c9284618a2e3a319fbe49baf",
            "2d7a96f85e32476081726c05472e7a1f",
            "848817129ebc4a56bfe7db2f36f7e8e4",
            "6f66b4a3c4654dff8a34ab70e8a7293f",
            "7156bdf26dc248f5ac80255c57261205"
          ]
        }
      },
      "source": [
        "from easydict import EasyDict\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "\n",
        "args = EasyDict({\n",
        "    'batch_size': 64,\n",
        "    'epochs': 100,\n",
        "    'validate_epoch':1,\n",
        "    'validate_batch': 1000,\n",
        "    'n_batch_validate': 100,\n",
        "    'emb_size' : 64,\n",
        "    'hidden_units': 100,\n",
        "    'lr': 0.001,\n",
        "    'beta_1': 0.9,\n",
        "    'beta_2': 0.999,\n",
        "    'dropout': 0.25,\n",
        "    'topk': 20,\n",
        "    'loss': 'bpr-max',\n",
        "    'activation': 'linear',\n",
        "    'session_key': 'session_id',\n",
        "    'item_key': 'track_id_clean',\n",
        "    'data_path': 'data/training',\n",
        "    'test_path': 'data/testing',\n",
        "    'idxs_path': 'item_idxs.json',\n",
        "    'input_form': 'one-hot',\n",
        "    'regularization': None,\n",
        "})\n",
        "\n",
        "train_model(args)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (64, 1, 360400)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_2 (CuDNNGRU)       [(64, 100), (64, 100)]    108150600 \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (64, 100)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, 360400)              36400400  \n",
            "=================================================================\n",
            "Total params: 144,551,000\n",
            "Trainable params: 144,551,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b322bbbb4a0f4a408d5287672af3c332",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating Model\n",
            "Recall@20: 0.057188\n",
            "MRR@20: 0.009239\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe3f3f364d3401aa21de060745f2be1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-83344b25050c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m })\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-e4259137bcbc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'crossentropy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m               \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6nAMKeWDGpY",
        "colab_type": "text"
      },
      "source": [
        "## Resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF2VY6LsDIrE",
        "colab_type": "text"
      },
      "source": [
        "Mini 14 epochs, cross-entropy:\n",
        "- Train Loss: 6.17\n",
        "- Val Loss: 7.12\n",
        "- Recall@20: 0.226\n",
        "- MRR@20: 0.056\n",
        "\n",
        "Mini Most Popular:\n",
        "- Recall@20: 0.10\n",
        "- MRR@20: 0.025\n",
        "\n",
        "Mini 20 epochs, bpr:\n",
        "- Train Loss: 0.04\n",
        "- Val Loss: 0.02\n",
        "- Recall@20: 0.11\n",
        "- MRR@20: 0.024\n",
        "\n",
        "1 epoch, 1 log file, cross-entropy:\n",
        "- Train Loss: 9.8\n",
        "- Recall@20: 0.24\n",
        "- MRR@20: 0.024\n",
        "\n",
        "Batch 17000, bpr:\n",
        "- Train Loss: 0.34\n",
        "- Recall@20: 0.127812\n",
        "- MRR@20: 0.017049"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcfSGdZCDIIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = tf.reshape(y_true, [-1])\n",
        "  y_true = tf.cast(y_true, tf.int64)\n",
        "  yhat = tf.gather(y_pred, y_true, axis=1)\n",
        "  yhatT = tf.transpose(yhat)\n",
        "  diag = tf.diag_part(yhat)\n",
        "  sig = tf.nn.sigmoid(diag-yhatT)\n",
        "  return tf.reduce_mean(-tf.log(sig))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPLwLh3idG2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "batch_size = 4\n",
        "n_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys7cyvyLdEdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "81a6fb51-0c37-45bf-c5b1-eb63bc5e45c6"
      },
      "source": [
        "y_pred = tf.constant(np.random.randn(batch_size,n_classes))\n",
        "y_true = tf.constant(np.random.randint(0,n_classes,size=(batch_size,1)))\n",
        "tf.Session().run(y_pred), tf.Session().run(y_true)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-05bf0ab17c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1Lhrt9xmT6o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "763ae5ae-b98a-46ab-fa53-e16ea7bb58aa"
      },
      "source": [
        "y_true = tf.reshape(y_true,[-1])\n",
        "print(tf.Session().run(y_true))\n",
        "gather = tf.gather(y_pred,y_true, axis=1) # get positive and negative scores\n",
        "diag = tf.diag_part(gather) # positive samples\n",
        "diag_exp = tf.expand_dims(diag, axis=0) # expand dim to transpose\n",
        "trans = tf.transpose(diag_exp) \n",
        "diff = trans - gather # diference between positive and all\n",
        "sig = tf.nn.sigmoid(diff)\n",
        "loss = tf.reduce_mean(-tf.log(sig))\n",
        "tf.Session().run(loss)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 3 0 3]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9183382802591877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ZhgwyWv0dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}